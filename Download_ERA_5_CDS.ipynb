{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpd19/Insect_Outbreaks/blob/main/Download_ERA_5_CDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "647AiRU-xB_m"
      },
      "source": [
        "# Download ERA-5 data from the climate data store using the API\n",
        "\n",
        "This document is stored on KP Dixon's drive and edits will not save, please make your own copy in your own drive to make edits by doing:\n",
        "\n",
        "`File > Save a copy in Drive`\n",
        "\n",
        "You must first have an ECMWF account to access data from the climate data store. After you get your account, you can get your personal access token, which you must paste in the first cell below to use the API.\n",
        "\n",
        "https://cds.climate.copernicus.eu/\n",
        "\n",
        "You must also accept the liscence agreement:\n",
        "\n",
        "https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download#manage-licences\n",
        "\n",
        "When you run the first cell in the notebook below, it will connect to the API and download important packages to your drive. You will also have to mount to your drive, so click yes/continue on the pop ups when the next cell runs. This allows you to save documents in your google drive. The `%cd` command will also change your working directory to Colab Notebooks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhtaKMAftdvb"
      },
      "source": [
        "%%capture\n",
        "### make a file in the root with the api location and your personal key\n",
        "!echo \"url:  https://cds.climate.copernicus.eu/api\" > $HOME/.cdsapirc\n",
        "#!echo \"key: your_key_here\" >> $HOME/.cdsapirc # insert personal access token from your account where it says your_key_here\n",
        "\n",
        "\n",
        "!echo \"key: aeee41fe-5ef8-49fd-bf6a-c881da527f19\" >> $HOME/.cdsapirc # insert personal access token from your account where it says your_key_here\n",
        "\n",
        "!pip install cdsapi>=0.7.2\n",
        "import cdsapi\n",
        "import os, shutil, numpy as np, xarray as xr\n",
        "from datetime import datetime\n",
        "from google.colab import drive; drive.mount('/content/drive/')\n",
        "\n",
        "%cd /content/drive/My Drive/Colab Notebooks/ # change working directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG1MjCHncFuE"
      },
      "source": [
        "This notebook includes several basic examples of downloading climate data from ERA5, which is a gridded reanalysis of historical weather data. The first example will be to download hourly data, the second example will be to download monthly data. I've also included some simple functions that will turn NetCDF files to dataframes, which are easier for most people to work with. You will have to adapt the functions based on the type of data you are downloading.\n",
        "\n",
        "The documentation for ERA5 can be found here:\n",
        "\n",
        "https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation\n",
        "\n",
        "Before downloading the data, you must first decide what you want to download and at what spatial and time scale:\n",
        "\n",
        "*   **Variable:** There is an abundance of weather variables that can be downloaded, which are detailed in the documentation. Variable examples: 2m_temperature, total_precipitation, relative_humidity\n",
        "*   **Spatial scale:** The default for the data is downloaded as 0.25 degree x 0.25 degree grid cells\n",
        "*   **Time scale:** The data can be downloaded as hourly data, which is going to take longer and be a larger file size, or monthly aggregated data.\n",
        "\n",
        "Below is an example of downloading the temperature at 2m (2m_temperature) for each hour for all the days in June 2020 for the state of Colorado. The file will be saved as a netCDF, which is a common file format for data with multiple dimensions (space, time).\n",
        "\n",
        "*   **Variable:** 2m_temperature\n",
        "*   **Spatial scale:** \"41/-109/37/-102\"\n",
        "*   **Time scale:** Hourly time scale\n",
        "\n",
        "Sometimes, the files will take a long time to aggregate and save to your drive, and your Google Colab will crash. However, your request will still be running in the system, which can be checked here:\n",
        "\n",
        "https://cds.climate.copernicus.eu/requests?tab=all\n",
        "\n",
        "You can also download your request from that website, if you don't feel like waiting for it to run in Google Colab. This request should only take a minute or so to run, and the NetCDF file will be saved in your drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpnCKgkJYKyT"
      },
      "source": [
        "c = cdsapi.Client()\n",
        "\n",
        "c.retrieve(\n",
        "    'reanalysis-era5-single-levels',\n",
        "    {\n",
        "        'product_type': 'reanalysis',\n",
        "        'variable': '2m_temperature',\n",
        "        'year': '2020',\n",
        "        'month': '06',\n",
        "        'day': [\n",
        "                '01', '02', '03',\n",
        "                '04', '05', '06',\n",
        "                '07', '08', '09',\n",
        "                '10', '11', '12',\n",
        "                '13', '14', '15',\n",
        "                '16', '17', '18',\n",
        "                '19', '20', '21',\n",
        "                '22', '23', '24',\n",
        "                '25', '26', '27',\n",
        "                '28', '29', '30',\n",
        "                '31',\n",
        "            ],\n",
        "            'time': [\n",
        "                '00:00', '01:00', '02:00',\n",
        "                '03:00', '04:00', '05:00',\n",
        "                '06:00', '07:00', '08:00',\n",
        "                '09:00', '10:00', '11:00',\n",
        "                '12:00', '13:00', '14:00',\n",
        "                '15:00', '16:00', '17:00',\n",
        "                '18:00', '19:00', '20:00',\n",
        "                '21:00', '22:00', '23:00',],\n",
        "        'format': 'netcdf',\n",
        "        'area' : \"41/-109/37/-102\"    # top/left/bottom/right\"\n",
        "    },\n",
        "    'colorado_june_2020_t2m.nc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting from NetCDF to easier to use dataframe format and downsampling from hourly to daily min, max, average"
      ],
      "metadata": {
        "id": "xsFbrVce-Dwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-g5BpJEr71MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample_temps(dataset):\n",
        "  \"\"\" Function to take hourly temperature data (K) from an xarray and resample to daily min, max, and average temperature (C) in a dataframe \"\"\"\n",
        "  dataset['t2m'] -= 273.15 # converting from Kelvin to Celcius\n",
        "  dataset.t2m.attrs['units'] = 'deg C' # updating the units\n",
        "  dataset = dataset.rename({'valid_time': 'time'})\n",
        "  max_daily = dataset.resample(time = 'D').max(dim = 'time') # resampling to get the max hourly temperature for each day\n",
        "  min_daily = dataset.resample(time = 'D').min(dim = 'time') # min temperature\n",
        "  mean_daily = dataset.resample(time = 'D').mean(dim = 'time') # average temperature\n",
        "\n",
        "  max_daily = max_daily.rename({'t2m':'max_t2m'}) # renaming variable accordingly\n",
        "  min_daily = min_daily.rename({'t2m':'min_t2m'})\n",
        "  mean_daily = mean_daily.rename({'t2m':'mean_t2m'})\n",
        "\n",
        "  merged_data = xr.merge([max_daily,min_daily,mean_daily]) # merging dataset\n",
        "\n",
        "  merged_data['year'] = merged_data['time'].dt.strftime('%Y') # getting the year from the date information\n",
        "  merged_data['month'] = merged_data['time'].dt.strftime('%B') # month\n",
        "  merged_data['day'] = merged_data['time'].dt.strftime('%d') # day\n",
        "\n",
        "  df = merged_data.to_dataframe() # converting xarray to dataframe\n",
        "  df = df.reset_index() # resetting the index\n",
        "\n",
        "  return(df)\n"
      ],
      "metadata": {
        "id": "-Tc-2OvA6_aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading in the xarray formatted data we just downloaded from the Climate Data Store:"
      ],
      "metadata": {
        "id": "-rpVrD6R9y9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_jun_xr = xr.open_dataset('colorado_june_2020_t2m.nc') # xarray formatted data we just downloa"
      ],
      "metadata": {
        "id": "ISPHfuEk6k32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets look at the format first, sometimes the variable names are different than what we expect based on updates to the Climate Data Store. The dataset used to say `time` and not it says `valid_time`. You'll have to update the downsampling function accordingly in future analyses. Also if you change the variable from temperature at 2m to something else, you will have to change that."
      ],
      "metadata": {
        "id": "kEBtUGPiLhML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_jun_xr"
      ],
      "metadata": {
        "id": "OII86GatLgGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using our function to convert the data:"
      ],
      "metadata": {
        "id": "RdSsdbIS-Rg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_jun_df = downsample_temps(col_jun_xr)"
      ],
      "metadata": {
        "id": "FLcg8rHI-Q8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have a dataframe that we can save:"
      ],
      "metadata": {
        "id": "-nV-Je6mOP7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_jun_df.to_csv(\"colorado_june_2020_t2m_df.csv\")"
      ],
      "metadata": {
        "id": "RzMVPR6hFcKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the new dataframe along a latitudinal gradient for one longitude value, to get an idea of the structure:"
      ],
      "metadata": {
        "id": "bD4MzSasKY0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_jun_df.loc[col_jun_df['longitude'] == -102.75].plot(kind = 'scatter', x = 'time',y = 'min_t2m', c = 'latitude')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hKNRiqHyFDSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1TrwchRADJT"
      },
      "source": [
        "## Monthly Precipitation for Colorado\n",
        "\n",
        "Below is an example of downloading the monthly total precipitation for 2010-2019 for the state of Colorado. The file will be saved as a netCDF.\n",
        "\n",
        "*   **Variable:** total_precipitation\n",
        "*   **Spatial scale:** \"41/-109/37/-102\"\n",
        "*   **Time scale:** Monthly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j54zYhcMcpWW"
      },
      "source": [
        "c = cdsapi.Client()\n",
        "\n",
        "c.retrieve(\n",
        "    'reanalysis-era5-single-levels-monthly-means',\n",
        "    {\n",
        "        'product_type': 'monthly_averaged_reanalysis',\n",
        "        'variable': 'total_precipitation',\n",
        "        'year': ['2010', '2011',\n",
        "            '2012', '2013', '2014',\n",
        "            '2015', '2016', '2017',\n",
        "            '2018', '2019',\n",
        "        ],\n",
        "        'month': [\n",
        "            '01', '02', '03',\n",
        "            '04', '05', '06',\n",
        "            '07', '08', '09',\n",
        "            '10', '11', '12',\n",
        "        ],\n",
        "        'time': '00:00',\n",
        "        'format': 'netcdf',\n",
        "        'area' : \"41/-109/37/-102\"    # top/left/bottom/right\"\n",
        "    },\n",
        "    'colorado_2010s_total_precipitation.nc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function takes monthly precipitation and converts it to a dataframe. The monthly dataset I downloaded gave me the date in the format '20100101' For January 1st, 2010, so I used `datetime` to convert it to a readable date."
      ],
      "metadata": {
        "id": "ng663JcZhFes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def monthly_precip(dataset):\n",
        "  \"\"\" Function to take monthly precipitation data and convert to dataframe \"\"\"\n",
        "  df = dataset.to_dataframe()\n",
        "  df = df.reset_index()\n",
        "\n",
        "  df['time'] = [datetime.strptime(str(int(date)), '%Y%m%d').strftime('%Y-%m-%d') for date in df['date']]\n",
        "  df['time'] = pd.DatetimeIndex(df['time'].values)\n",
        "\n",
        "\n",
        "  df['year'] = df['time'].dt.strftime('%Y')\n",
        "  df['month'] = df['time'].dt.strftime('%B')\n",
        "  df = df[['latitude','longitude','tp','time','year','month']]\n",
        "\n",
        "\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "_cmM3TB0LRgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2va4JCic48y"
      },
      "source": [
        "col_precip_xr = xr.open_dataset('colorado_2010s_total_precipitation.nc', decode_times = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_precip_xr"
      ],
      "metadata": {
        "id": "faioidbZeUiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets again look at our dataset and update the function accordingly:"
      ],
      "metadata": {
        "id": "8yf-41jPL6xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to dataframe:"
      ],
      "metadata": {
        "id": "GxlXcykfR3tN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_precip_df = monthly_precip(col_precip_xr)"
      ],
      "metadata": {
        "id": "t4UCU4T5R6tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_precip_df"
      ],
      "metadata": {
        "id": "gQ-6J4vNeQc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPhdn2-7ldaJ"
      },
      "source": [
        "col_precip_df.to_csv(\"colorado_2010s_tp_monthly.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time we can generate a map of November total precipitation in 2019 across Colorado:"
      ],
      "metadata": {
        "id": "9uFuPtwygssz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat = col_precip_df.loc[col_precip_df['time'] == '2019-11-01'][['latitude','longitude','tp']].pivot(index = 'latitude',columns = 'longitude',values = 'tp')\n",
        "\n",
        "plt.pcolor(dat)\n",
        "plt.yticks(np.arange(0.5, len(dat.index), 1), dat.index)\n",
        "plt.xticks(np.arange(0.5, len(dat.columns), 1), dat.columns)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dVB8iM6kSJWy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}